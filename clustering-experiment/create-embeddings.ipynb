{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846e53e6-d9e7-45bc-849c-44e9eaef2ee9",
   "metadata": {},
   "source": [
    "# Create Embeddings\n",
    "Embeddings will be useful in experiment notebooks for things like topic clustering. They are computed and saved in this dedicated notebook, because computation might take quite some time depending on hardware and used model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f42c9b9-8b20-4c19-a4fa-f1a87f0ca0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0999e2e-ba73-49f5-b184-137ac6698980",
   "metadata": {},
   "source": [
    "## Input/Output Setup\n",
    "Define where to load *pickled* documents from and how to store outputs (document splits and embedding vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2650aa-ecbc-4dd7-88d2-61bc285a291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "DOCS_PICKLE_FILE = \"reddit-docs.pickle\"\n",
    "# output\n",
    "SPLITS_PICKLE_PREFIX = \"reddit-splits\"\n",
    "VECS_PICKLE_PREFIX = \"reddit-vecs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c7762-53e8-4802-8ad8-ad297088320b",
   "metadata": {},
   "source": [
    "## Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b2bad6-6dc4-4d40-b69c-a3315909fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DOCS_PICKLE_FILE, \"rb\") as file:\n",
    "    docs = pickle.load(file)\n",
    "print(f\"{len(docs)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f05888b-86b6-4948-914d-9f6522c43a9f",
   "metadata": {},
   "source": [
    "## Split Documents\n",
    "Split all docs to make them fit as context (or input) of a local llm.\n",
    "\n",
    "**Dependencies**: `CHUNK_SIZE` and `CHUNK_OVERLAP` depend on the used LLM for embeddings (context size) and might also impact the overall outcome depending on the experiment setup. Should be chosen carefully and maybe also experimented with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e612670e-6647-4ca0-90d4-809eed04b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3595a9fe-d190-4e34-84d4-6279f6be0d83",
   "metadata": {},
   "source": [
    "### Compute Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddeb7a9-bc71-4054-a3cd-5da3591e61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    add_start_index=True\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(f\"{len(splits)} splits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b23207-b318-4e5b-88ca-1281cf2ec48e",
   "metadata": {},
   "source": [
    "### Save Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e63122-45ad-4699-88a1-39049ff2d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_filename = f\"{SPLITS_PICKLE_PREFIX}-{CHUNK_SIZE}-{CHUNK_OVERLAP}.pickle\"\n",
    "with open(splits_filename, \"wb\") as file:\n",
    "    pickle.dump(splits, file)\n",
    "    print(f\"Wrote splits to {splits_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e38c8a5-91bf-4d97-968a-bbed524cb427",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "**Experiments**: Different LLMs (obviously)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db3a40-f86b-4d79-b6f5-79e5990ceec5",
   "metadata": {},
   "source": [
    "### Setup LLM\n",
    "Uses *Ollama*: https://ollama.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea13f8a-1511-49cb-9c46-928f4ed467a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_MODEL = \"llama3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843bbe52-6b7c-4ea9-9bca-562f155c8654",
   "metadata": {},
   "source": [
    "### Compute Embedding Vectors\n",
    "Computes embedding vectors for all document *splits*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e3b053-3597-47c8-8ebc-bf88834b1449",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=OLLAMA_MODEL)\n",
    "vecs = []\n",
    "for split in tqdm(splits):\n",
    "    vecs.append(embeddings.embed_documents([split])[0])\n",
    "print(f\"embedding space dim: {len(vecs[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1520210f-6fcd-4121-9cc9-99ef9e70b5c7",
   "metadata": {},
   "source": [
    "### Save Embedding Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e833806-e982-4224-9778-a5b957d11a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_filename = f\"{VECS_PICKLE_PREFIX}-{CHUNK_SIZE}-{CHUNK_OVERLAP}.pickle\"\n",
    "with open(vecs_filename, \"wb\") as file:\n",
    "    pickle.dump(vecs, file)\n",
    "    print(f\"Wrote embedding vecs for splits to {vecs_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
