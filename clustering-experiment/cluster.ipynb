{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b13990e-0994-48f7-af9d-5a8797d5ab74",
   "metadata": {},
   "source": [
    "Load previously downloaded Wikipedia docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc154b-ab87-4839-94f8-203b25d894b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"docs.pickle\", \"rb\") as file:\n",
    "    docs = pickle.load(file)\n",
    "print(f\"{len(docs)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386fbc2-c464-4412-bf2c-7872c2705472",
   "metadata": {},
   "source": [
    "Split all docs to make them fit as context (or input) of a local llm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d85202-2fc9-4ebf-85ae-6f2bc9552c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(f\"{len(splits)} splits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4463d4-6f4b-49cc-b117-4c7e08432237",
   "metadata": {},
   "source": [
    "Create embedding vectors for all splits using some Ollama-served llm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da8143-6e04-420d-88f9-26e960674cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama3\")\n",
    "vecs = []\n",
    "for split in tqdm(splits):\n",
    "    vecs.append(embeddings.embed_documents([split])[0])\n",
    "print(f\"embedding space dim: {len(vecs[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd4164-953d-4944-a95d-3a0c8173ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vecs.pickle\", \"wb\") as file:\n",
    "    pickle.dump(vecs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd6663-e047-4e3a-bc7c-53ff7f91ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#clusters = DBSCAN(eps=.5, min_samples=3).fit(vecs)\n",
    "clusters = KMeans(n_clusters=10).fit(vecs)\n",
    "labels = clusters.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4470a-e862-40e6-8067-1cb10c452ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([l for l in labels if l > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe513a9-eca3-4710-9f15-2362f9b318c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get back texts for labeled vecs stored in vector store\n",
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"wikidocs\")\n",
    "ids=[str(i) for i in range(len(splits))]\n",
    "collection.add(\n",
    "    documents=[d.page_content for d in splits],\n",
    "    embeddings=vecs,\n",
    "    metadatas=[d.metadata for d in splits],\n",
    "    ids=ids\n",
    ")\n",
    "print(f\"{collection.count()} docs added to Chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb3aa3c-a702-4611-845c-5549f1738f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve docs\n",
    "unique_labels = set([l for l in labels if l > 0])\n",
    "query_embeddings = []\n",
    "for label in unique_labels:\n",
    "    ix = list(labels).index(label)\n",
    "    query_embeddings.append(vecs[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53c5bf2-d3d0-474b-bad2-0f53198849cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "representatives = collection.query(\n",
    "    query_embeddings=query_embeddings,\n",
    "    n_results=5,\n",
    "    include=[\"documents\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa861f-658b-48f0-a4a8-dd295794f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask LLM for single term/tag\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = Ollama(model=\"llama3\")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Summarize in maximum three words. No other output.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "for response in representatives[\"documents\"]:\n",
    "    for text in response:\n",
    "        print(chain.invoke({ \"input\": text }))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
