{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b13990e-0994-48f7-af9d-5a8797d5ab74",
   "metadata": {},
   "source": [
    "Load previously downloaded Wikipedia docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ddc154b-ab87-4839-94f8-203b25d894b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 documents\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"docs.pickle\", \"rb\") as file:\n",
    "    docs = pickle.load(file)\n",
    "print(f\"{len(docs)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386fbc2-c464-4412-bf2c-7872c2705472",
   "metadata": {},
   "source": [
    "Split all docs to make them fit as context (or input) of a local llm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9d85202-2fc9-4ebf-85ae-6f2bc9552c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1699 splits\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(f\"{len(splits)} splits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4463d4-6f4b-49cc-b117-4c7e08432237",
   "metadata": {},
   "source": [
    "Create embedding vectors for all splits using some Ollama-served llm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02da8143-6e04-420d-88f9-26e960674cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c3f3cffff241ed8129510ac1ec3741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1699 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding space dim: 4096\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama3\")\n",
    "vecs = []\n",
    "for split in tqdm(splits):\n",
    "    vecs.append(embeddings.embed_documents([split])[0])\n",
    "print(f\"embedding space dim: {len(vecs[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97cd4164-953d-4944-a95d-3a0c8173ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vecs.pickle\", \"wb\") as file:\n",
    "    pickle.dump(vecs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "24cd6663-e047-4e3a-bc7c-53ff7f91ff4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 10\n",
      "Estimated number of noise points: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#clusters = DBSCAN(eps=.5, min_samples=3).fit(vecs)\n",
    "clusters = KMeans(n_clusters=10).fit(vecs)\n",
    "labels = clusters.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a3b4470a-e862-40e6-8067-1cb10c452ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 6, 8, 3, 3, 6, 3, 3, 6, 8, 7, 5, 8, 6, 6, 9, 6, 7, 8, 7, 6, 7, 6, 9, 8, 9, 9, 6, 6, 6, 6, 4, 7, 3, 6, 5, 7, 9, 8, 7, 8, 8, 8, 1, 9, 8, 3, 7, 5, 8, 3, 6, 4, 6, 3, 5, 4, 4, 5, 9, 9, 1, 6, 5, 8, 5, 6, 7, 9, 5, 9, 5, 6, 8, 8, 9, 6, 6, 8, 8, 7, 9, 7, 9, 8, 9, 3, 3, 3, 5, 5, 6, 9, 5, 9, 7, 7, 7, 5, 6, 7, 3, 9, 4, 7, 3, 3, 5, 7, 6, 6, 1, 7, 4, 7, 3, 3, 7, 6, 3, 3, 7, 7, 3, 3, 5, 4, 3, 4, 6, 3, 4, 7, 7, 5, 7, 7, 7, 9, 6, 7, 9, 7, 7, 7, 5, 8, 4, 7, 4, 6, 4, 4, 6, 9, 6, 9, 7, 6, 6, 7, 3, 6, 3, 5, 7, 7, 7, 7, 6, 2, 6, 9, 8, 6, 8, 6, 4, 7, 3, 4, 3, 7, 8, 4, 3, 3, 9, 7, 7, 9, 9, 6, 9, 3, 7, 7, 6, 7, 6, 7, 3, 4, 9, 1, 1, 1, 1, 9, 6, 6, 7, 7, 3, 5, 4, 7, 3, 7, 3, 3, 7, 7, 1, 7, 9, 4, 4, 7, 7, 7, 6, 8, 7, 6, 4, 7, 5, 9, 1, 4, 2, 4, 3, 6, 6, 9, 4, 4, 7, 7, 4, 5, 9, 6, 9, 9, 9, 9, 9, 9, 6, 9, 9, 9, 8, 7, 8, 9, 4, 7, 5, 9, 8, 3, 4, 4, 4, 7, 9, 7, 9, 8, 6, 6, 7, 7, 9, 6, 7, 7, 5, 6, 9, 9, 3, 3, 7, 7, 7, 7, 9, 1, 9, 3, 7, 7, 7, 3, 7, 4, 4, 6, 4, 4, 7, 9, 3, 3, 7, 3, 3, 6, 4, 7, 7, 7, 9, 4, 4, 4, 3, 4, 6, 9, 7, 7, 7, 9, 4, 7, 7, 8, 4, 4, 4, 4, 4, 7, 8, 6, 3, 3, 3, 7, 6, 7, 4, 7, 6, 7, 4, 3, 3, 3, 7, 4, 9, 4, 7, 6, 4, 6, 3, 6, 4, 7, 6, 4, 7, 7, 7, 9, 4, 7, 7, 7, 5, 4, 3, 3, 4, 7, 6, 4, 4, 4, 3, 4, 7, 4, 7, 9, 7, 7, 7, 5, 9, 4, 7, 7, 9, 4, 8, 7, 7, 7, 6, 3, 7, 7, 1, 7, 9, 7, 3, 4, 9, 4, 3, 4, 1, 3, 5, 9, 7, 7, 7, 5, 6, 7, 5, 7, 7, 8, 7, 7, 4, 8, 4, 6, 4, 7, 7, 8, 8, 5, 4, 8, 7, 3, 7, 6, 4, 4, 7, 4, 7, 7, 6, 4, 7, 7, 4, 7, 7, 6, 8, 6, 6, 7, 9, 4, 6, 7, 7, 9, 4, 4, 4, 8, 8, 6, 8, 6, 7, 6, 6, 9, 7, 3, 4, 9, 4, 7, 7, 7, 4, 6, 4, 4, 4, 8, 7, 9, 4, 7, 7, 7, 7, 9, 4, 7, 7, 4, 7, 4, 4, 6, 7, 7, 7, 6, 4, 3, 4, 7, 4, 6, 4, 4, 4, 4, 6, 6, 8, 8, 7, 8, 4, 8, 4, 7, 7, 4, 4, 4, 4, 4, 4, 6, 8, 7, 7, 7, 6, 4, 3, 7, 7, 4, 3, 6, 4, 6, 4, 6, 9, 3, 4, 7, 7, 7, 9, 4, 7, 5, 3, 7, 3, 7, 3, 6, 4, 3, 3, 3, 4, 4, 3, 6, 3, 3, 7, 5, 3, 3, 9, 3, 4, 4, 3, 3, 6, 8, 3, 3, 3, 3, 1, 4, 3, 3, 3, 4, 4, 4, 3, 4, 7, 3, 6, 3, 5, 3, 4, 5, 7, 3, 4, 9, 4, 7, 3, 5, 4, 4, 9, 3, 3, 6, 3, 7, 7, 7, 9, 4, 4, 4, 4, 4, 4, 1, 4, 4, 1, 8, 7, 6, 3, 4, 6, 8, 3, 3, 3, 3, 3, 3, 6, 6, 4, 3, 4, 1, 3, 5, 4, 3, 3, 3, 4, 3, 3, 3, 7, 4, 9, 3, 7, 7, 6, 7, 6, 4, 3, 9, 3, 3, 7, 9, 8, 6, 3, 3, 3, 7, 6, 7, 3, 7, 7, 7, 3, 7, 7, 9, 1, 9, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 3, 3, 9, 3, 1, 3, 7, 3, 3, 6, 8, 3, 1, 2, 9, 2, 2, 2, 9, 8, 6, 1, 1, 1, 9, 1, 9, 8, 1, 4, 8, 2, 1, 7, 6, 8, 8, 6, 9, 9, 8, 8, 8, 8, 7, 6, 3, 1, 3, 3, 3, 1, 1, 1, 2, 9, 9, 4, 4, 1, 4, 1, 6, 8, 3, 7, 3, 3, 4, 6, 4, 4, 1, 6, 7, 9, 1, 1, 1, 1, 1, 9, 1, 1, 9, 1, 6, 8, 6, 3, 7, 3, 5, 1, 3, 1, 1, 1, 5, 1, 1, 1, 1, 1, 9, 1, 1, 1, 1, 1, 9, 1, 1, 1, 1, 1, 1, 4, 3, 4, 1, 1, 1, 1, 1, 9, 1, 1, 1, 1, 6, 5, 8, 6, 1, 1, 1, 1, 1, 1, 9, 4, 1, 1, 4, 4, 5, 1, 3, 1, 1, 1, 6, 8, 3, 1, 1, 1, 8, 9, 1, 1, 1, 1, 1, 6, 1, 1, 6, 1, 5, 9, 3, 3, 4, 9, 3, 9, 4, 1, 3, 3, 3, 1, 5, 4, 3, 3, 3, 3, 4, 6, 1, 3, 1, 1, 5, 1, 2, 1, 2, 1, 9, 1, 3, 1, 4, 1, 6, 3, 3, 1, 1, 3, 3, 6, 2, 2, 2, 2, 2, 9, 2, 2, 2, 2, 9, 3, 2, 2, 2, 2, 3, 6, 1, 2, 1, 2, 2, 9, 2, 2, 2, 2, 2, 9, 9, 2, 2, 2, 2, 9, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 9, 2, 3, 2, 2, 2, 2, 6, 2, 2, 2, 2, 6, 2, 9, 2, 2, 6, 9, 3, 3, 8, 4, 8, 7, 7, 4, 5, 8, 8, 3, 2, 3, 4, 5, 9, 2, 9, 2, 2, 2, 9, 3, 2, 1, 2, 1, 5, 8, 2, 6, 6, 7, 5, 4, 4, 4, 4, 4, 8, 3, 4, 4, 4, 5, 2, 2, 9, 2, 2, 9, 3, 9, 3, 2, 9, 2, 9, 2, 2, 2, 2, 2, 9, 8, 8, 6, 2, 7, 3, 3, 6, 8, 3, 9, 4, 7, 9, 8, 3, 3, 3, 1, 5, 3, 3, 3, 3, 3, 5, 3, 2, 2, 3, 3, 9, 6, 2, 2, 7, 6, 4, 6, 9, 2, 9, 2, 2, 2, 9, 8, 6, 2, 2, 5, 2, 2, 9, 2, 2, 5, 4, 3, 3, 3, 3, 5, 8, 6, 4, 4, 2, 5, 1, 2, 1, 2, 9, 3, 1, 3, 5, 3, 3, 3, 6, 4, 3, 3, 4, 4, 5, 3, 3, 7, 3, 3, 3, 6, 9, 2, 9, 9, 1, 2, 2, 2, 5, 2, 2, 5, 3, 3, 7, 3, 5, 1, 9, 2, 2, 2, 5, 3, 3, 6, 3, 7, 5, 5, 2, 2, 2, 2, 2, 9, 1, 9, 1, 3, 1, 1, 3, 9, 8, 4, 4, 6, 7, 3, 3, 3, 3, 9, 8, 1, 3, 3, 3, 3, 6, 3, 1, 1, 8, 1, 5, 1, 1, 6, 3, 7, 1, 1, 1, 6, 4, 3, 4, 4, 3, 8, 4, 3, 3, 3, 8, 3, 3, 3, 3, 6, 1, 4, 6, 1, 1, 6, 4, 1, 1, 3, 3, 1, 6, 8, 1, 3, 4, 3, 1, 3, 7, 6, 8, 8, 3, 3, 3, 3, 6, 4, 4, 1, 1, 8, 1, 1, 1, 1, 1, 1, 9, 8, 1, 1, 3, 4, 3, 3, 3, 3, 6, 1, 1, 7, 1, 1, 9, 8, 7, 7, 7, 4, 6, 1, 1, 1, 6, 2, 1, 6, 1, 9, 8, 4, 7, 3, 7, 6, 4, 3, 4, 4, 4, 4, 3, 7, 6, 7, 1, 5, 4, 4, 3, 4, 7, 4, 7, 7, 7, 6, 8, 8, 4, 4, 8, 3, 4, 3, 6, 8, 4, 6, 6, 4, 7, 5, 8, 3, 8, 8, 8, 7, 6, 4, 4, 4, 4, 4, 5, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 5, 7, 7, 6, 4, 4, 4, 4, 7, 7, 6, 4, 3, 1, 9, 6, 4, 4, 3, 3, 5, 8, 6, 4, 8, 7, 7, 7, 4, 7, 4, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "print([l for l in labels if l > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8fe513a9-eca3-4710-9f15-2362f9b318c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1699 docs added to Chroma\n"
     ]
    }
   ],
   "source": [
    "# get back texts for labeled vecs stored in vector store\n",
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"wikidocs\")\n",
    "ids=[str(i) for i in range(len(splits))]\n",
    "collection.add(\n",
    "    documents=[d.page_content for d in splits],\n",
    "    embeddings=vecs,\n",
    "    metadatas=[d.metadata for d in splits],\n",
    "    ids=ids\n",
    ")\n",
    "print(f\"{collection.count()} docs added to Chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4eb3aa3c-a702-4611-845c-5549f1738f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve docs\n",
    "unique_labels = set([l for l in labels if l > 0])\n",
    "query_embeddings = []\n",
    "for label in unique_labels:\n",
    "    ix = list(labels).index(label)\n",
    "    query_embeddings.append(vecs[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c53c5bf2-d3d0-474b-bad2-0f53198849cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "representatives = collection.query(\n",
    "    query_embeddings=query_embeddings,\n",
    "    n_results=5,\n",
    "    include=[\"documents\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e0fa861f-658b-48f0-a4a8-dd295794f2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phenomenology Origin\n",
      "Naturalism History\n",
      "Phenomenal Understanding\n",
      "Reality Study\n",
      "Islamic Philosophy\n",
      "Logic Definition\n",
      "Logic Summary\n",
      "Correct Argument Form\n",
      "Formal Logic\n",
      "Logic Argument\n",
      "Ancient Greek Thinkers\n",
      "Pythagoras Philosophy\n",
      "Epistemology & Ontology\n",
      "Sophist thinkers relativism\n",
      "Ancient Computing Tools\n",
      "Doctor of Philosophy\n",
      "Love of Wisdom\n",
      "PhD Research Degree\n",
      "PhD Degree Requirements\n",
      "Social Science Field\n",
      "Professionalization Process\n",
      "Philosophy Professionalization\n",
      "Social Science Roots\n",
      "Psychology Integration\n",
      "New philosophers.\n",
      "Love of wisdom\n",
      "Word Origin\n",
      "Philosophy Basics\n",
      "Indian Philosophical\n",
      "Reality Study\n",
      "System: Three-Word Summary: \"Process Started\"\n",
      "A definition\n",
      "Launch Successful\n",
      "Launchpad\n",
      "Three-word summary: Definition Library\n",
      "Western Philosophy\n",
      "Political Science\n",
      "AI Model Collapse\n",
      "Music Genre Categories\n",
      "AI Recommendation\n",
      "Academic Philoso\n",
      "Professionalization Shift\n",
      "Political Science History\n",
      "Human Self-Mastery\n",
      "Philosophy's evolution\n"
     ]
    }
   ],
   "source": [
    "# ask LLM for single term/tag\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = Ollama(model=\"llama3\")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Summarize in maximum three words. No other output.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "for response in representatives[\"documents\"]:\n",
    "    for text in response:\n",
    "        print(chain.invoke({ \"input\": text }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1ee7b078-b54b-4f8f-8c82-e4d2716cde2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['work in the now specializing and restricted field of academic philosophy. These new philosophers functioned in independent departments of philosophy [...] They were making real gains in their research, creating a body of philosophic work that remains central to our study even now. These new philosophers also set their own standards for success, publishing in the recognized organs of philosophy that were being founded at the time: The Monist (1890), The International Journal of Ethics (1890), The Philosophical Review (1892), and The Journal of Philosophy, Psychology,']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representatives[\"documents\"][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c37f7-be99-4c3b-b705-2f99eee80b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
